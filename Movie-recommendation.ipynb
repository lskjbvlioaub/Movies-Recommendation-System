{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6663,"sourceType":"datasetVersion","datasetId":3405},{"sourceId":432507,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":352593,"modelId":373875}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.nn.functional import mse_loss\n\nfrom surprise import Dataset, Reader\nfrom surprise.model_selection import train_test_split, GridSearchCV\nfrom surprise import Reader, Dataset, SVD, SlopeOne, accuracy\n\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport ast","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:43:10.515764Z","iopub.execute_input":"2025-06-12T01:43:10.516360Z","iopub.status.idle":"2025-06-12T01:43:10.527908Z","shell.execute_reply.started":"2025-06-12T01:43:10.516330Z","shell.execute_reply":"2025-06-12T01:43:10.526455Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def extract_actor_name(cast_list, target_order):\n    cast_list = list(cast_list)\n    if isinstance(cast_list, list):\n        for member in cast_list:\n            if isinstance(member, dict) and member.get('order') == target_order:\n                return member.get('name')\n    return np.nan  \n\ndef get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan\ndef filter_keywords(x):\n    words = []\n    for i in x:\n        if i in s:\n            words.append(i)\n    return words\n\n\ncredits = pd.read_csv('/kaggle/input/the-movies-dataset/credits.csv')\nkeywords = pd.read_csv('/kaggle/input/the-movies-dataset/keywords.csv')\nmovies = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')\nratings = pd.read_csv('/kaggle/input/the-movies-dataset/ratings.csv')\n\nkeywords['id'] = keywords['id'].astype('int')\ncredits['id'] = credits['id'].astype('int')\n\nmovies = movies.drop([19730, 29503, 35587])\nmovies['id'] = movies['id'].astype('int')\nmovies['genres'] = movies['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\nprint(\"Movies before empty genres filter: \", len(movies))\nmovies = movies[movies['genres'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\nprint(\"Movies after empty genres filter: \", len(movies))\nmovies['description'] = movies['overview']\nmovies['description'] = movies['description'].fillna('')\nmovies = movies.merge(credits, on='id')\nmovies = movies.merge(keywords, on='id')\nmovies['cast'] = movies['cast'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n\n#Add top 5 actors\nfor i in range(5):\n    movies[f'order_{i}'] = movies['cast'].apply(lambda x: extract_actor_name(x, i))\n\ncolumns_take = ['genres', 'id', 'title', 'description', 'cast', 'crew', 'keywords', 'order_0', 'order_1', 'order_2', 'order_3', 'order_4']\nall_columns = movies.columns\ncolumns_drop = [column for column in all_columns if column not in columns_take]\nmovies = movies.drop(columns=columns_drop)\n\n#movies['cast'] = movies['cast'].apply(literal_eval)\nmovies['crew'] = movies['crew'].apply(literal_eval)\nmovies['keywords'] = movies['keywords'].apply(literal_eval)\n\nmovies['director'] = movies['crew'].apply(get_director)\nmovies['cast'] = movies['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\nmovies['cast'] = movies['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\nmovies['keywords'] = movies['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\nprint(\"Movies before empty keywords filter: \", len(movies))\nmovies = movies[movies['keywords'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\nprint(\"Movies after empty keywords filter: \", len(movies))\nmovies['cast'] = movies['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\nmovies['director'] = movies['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\nmovies['director'] = movies['director'].apply(lambda x: [x,x, x])\n\nglobal s\ns = movies.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\ns.name = 'keyword'\ns = s.value_counts()\ns = s[s > 1]\n\nstemmer = SnowballStemmer('english')\n\nmovies['keywords'] = movies['keywords'].apply(filter_keywords)\nmovies['keywords'] = movies['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\nmovies['keywords'] = movies['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\nmovies['soup'] = movies['keywords'] + movies['cast'] + movies['director'] + movies['genres']\nmovies['soup'] = movies['soup'].apply(lambda x: ' '.join(x))\n\navg_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\navg_ratings.rename(columns={'rating': 'avg_rating'}, inplace=True)\nmovies = movies.merge(avg_ratings, how='left', left_on='id', right_on='movieId')\nmovies.drop(columns=['movieId'], inplace=True)\n\n#movies = movies[:500]\n\nmovie_ids_in_ratings = ratings['movieId'].unique()\nprint(f\"Number of movie IDs in ratings dataframe: {len(movie_ids_in_ratings)}\")\nmovie_ids_in_movies = movies['id'].unique()\nprint(f\"Number of movie IDs in movies dataframe: {len(movie_ids_in_movies)}\")\n\nmissing_ids_ratings = [movie_id for movie_id in movie_ids_in_ratings \n                    if movie_id not in movie_ids_in_movies]\nmissing_ids_movies = [movie_id for movie_id in movie_ids_in_movies \n                    if movie_id not in movie_ids_in_ratings]\n\nprint(f\"Number of movie IDs present in ratings but missing from movies: {len(missing_ids_ratings)}\")\nprint(f\"Percentage of missing movies: {len(missing_ids_ratings) / len(movie_ids_in_ratings) * 100:.2f}%\")\n\nprint(f\"Number of movie IDs present in movies but missing from ratings: {len(missing_ids_movies)}\")\nprint(f\"Percentage of missing movies: {len(missing_ids_movies) / len(movie_ids_in_movies) * 100:.2f}%\")\n# Ensure consistent types\nmovies['id'] = movies['id'].astype(int)\nratings['movieId'] = ratings['movieId'].astype(int)\n\nvalid_movie_ids = set(movies['id'])  # Convert to set for fast lookup\n\nratings = ratings[ratings['movieId'].isin(valid_movie_ids)]\nmovies = movies[movies['id'].isin(ratings['movieId'].unique())]\nprint(f\"New number of rows in ratings after removing invalid movie IDs: {len(ratings)}\")\nmovies = movies.drop_duplicates(subset='id', keep='first')\nnum_users = ratings['userId'].nunique()\nnum_items = ratings['movieId'].nunique()\n\nuser_mapping = {id: idx for idx, id in enumerate(ratings['userId'].unique())}\nitem_mapping = {id: idx for idx, id in enumerate(ratings['movieId'].unique())}\n#convert non-sequential user IDs to sequential indices for matrix factorization\nratings['userId'] = ratings['userId'].map(user_mapping)\nratings['movieId'] = ratings['movieId'].map(item_mapping)\nmovies['id'] = movies['id'].map(item_mapping)\nmovies.drop(columns=['crew', 'cast'], inplace=True)\nratings.drop(columns=['timestamp'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:43:10.529753Z","iopub.execute_input":"2025-06-12T01:43:10.530092Z","iopub.status.idle":"2025-06-12T01:44:40.121612Z","shell.execute_reply.started":"2025-06-12T01:43:10.530059Z","shell.execute_reply":"2025-06-12T01:44:40.120393Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3715918233.py:24: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n  movies = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')\n","output_type":"stream"},{"name":"stdout","text":"Movies before empty genres filter:  45463\nMovies after empty genres filter:  43021\nMovies before empty keywords filter:  44104\nMovies after empty keywords filter:  31362\nNumber of movie IDs in ratings dataframe: 45115\nNumber of movie IDs in movies dataframe: 30728\nNumber of movie IDs present in ratings but missing from movies: 39481\nPercentage of missing movies: 87.51%\nNumber of movie IDs present in movies but missing from ratings: 25094\nPercentage of missing movies: 81.66%\nNew number of rows in ratings after removing invalid movie IDs: 10911543\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"movies.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:40.123054Z","iopub.execute_input":"2025-06-12T01:44:40.123416Z","iopub.status.idle":"2025-06-12T01:44:40.130414Z","shell.execute_reply.started":"2025-06-12T01:44:40.123392Z","shell.execute_reply":"2025-06-12T01:44:40.129158Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Index(['genres', 'id', 'title', 'description', 'keywords', 'order_0',\n       'order_1', 'order_2', 'order_3', 'order_4', 'director', 'soup',\n       'avg_rating'],\n      dtype='object')"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from collections import Counter\n\nall_genres = movies['genres'].explode()  \ngenre_counts = Counter(all_genres)\ngenre_counts_df = pd.DataFrame(genre_counts.items(), columns=['genre', 'count']).sort_values(by='count', ascending=False)\n\nprint(genre_counts_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:40.133213Z","iopub.execute_input":"2025-06-12T01:44:40.134322Z","iopub.status.idle":"2025-06-12T01:44:40.161886Z","shell.execute_reply.started":"2025-06-12T01:44:40.134278Z","shell.execute_reply":"2025-06-12T01:44:40.160778Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"              genre  count\n7             Drama   2991\n1            Comedy   1601\n8          Thriller   1222\n5            Action    989\n9           Romance    971\n6             Crime    791\n3         Adventure    629\n13           Horror    607\n10  Science Fiction    524\n11          Mystery    414\n4           Fantasy    401\n16      Documentary    309\n2            Family    304\n14          History    262\n12            Music    204\n15              War    188\n17          Western    167\n0         Animation    157\n18          Foreign    145\n19         TV Movie     56\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"len(ratings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:40.162991Z","iopub.execute_input":"2025-06-12T01:44:40.163356Z","iopub.status.idle":"2025-06-12T01:44:40.179790Z","shell.execute_reply.started":"2025-06-12T01:44:40.163333Z","shell.execute_reply":"2025-06-12T01:44:40.178688Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"10911543"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(ratings['movieId'].max())\nprint(len(movies))\nprint(movies['id'].max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:40.181184Z","iopub.execute_input":"2025-06-12T01:44:40.181549Z","iopub.status.idle":"2025-06-12T01:44:40.212858Z","shell.execute_reply.started":"2025-06-12T01:44:40.181515Z","shell.execute_reply":"2025-06-12T01:44:40.211939Z"}},"outputs":[{"name":"stdout","text":"5633\n5634\n5633\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"rating_counts = ratings['movieId'].value_counts()\npopular_movie_ids = rating_counts[rating_counts > 100].index\n\n# Step 3: Filter ratings and movies DataFrames\nfiltered_ratings = ratings[ratings['movieId'].isin(popular_movie_ids)].copy()\nfiltered_movies = movies[movies['id'].isin(popular_movie_ids)].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:40.213949Z","iopub.execute_input":"2025-06-12T01:44:40.214209Z","iopub.status.idle":"2025-06-12T01:44:41.378454Z","shell.execute_reply.started":"2025-06-12T01:44:40.214189Z","shell.execute_reply":"2025-06-12T01:44:41.377603Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:41.379569Z","iopub.execute_input":"2025-06-12T01:44:41.379832Z","iopub.status.idle":"2025-06-12T01:44:41.385913Z","shell.execute_reply.started":"2025-06-12T01:44:41.379808Z","shell.execute_reply":"2025-06-12T01:44:41.384905Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"\"\"\"\nreader = Reader(rating_scale=(0.5, 5))\ndata = Dataset.load_from_df(filtered_ratings[['userId', 'movieId', 'rating']], reader)\n\n# Define hyperparameter grid\nsim_options = {\n    \"n_factors\": [x * 50 for x in range(2,6)],\n    \"n_epochs\": [x * 10 for x in range(4, 7)],\n    \"lr_all\": [x / 50 for x in range(1,3)],\n    \"reg_all\": [0.01, 0.02]\n\n}\n#param_grid = {\"sim_options\": sim_options}\n\nsplit = 5\ngs = GridSearchCV(SVD, sim_options,\n                   measures=['rmse', 'mae'], cv=split, \n                   n_jobs=6, refit=False)\ngs.fit(data)\n\ndef print_results_table(gs_results, param_name):\n    print(f\"\\nResults for '{param_name}':\")\n    results_df = pd.DataFrame(gs_results)\n\n    # Filter columns to only include 'mean_test_rmse', 'mean_test_mae' and the parameter\n    param_col = f'param_{param_name}'\n    relevant_columns = [param_col, 'mean_test_rmse', 'mean_test_mae']\n    filtered_results = results_df[relevant_columns]\n\n    # Group by the parameter and calculate the mean of RMSE and MAE\n    # This is crucial because gs.cv_results contains all combinations,\n    # so we need to average across other parameters for a clean view of one.\n    grouped_results = filtered_results.groupby(param_col).agg(\n        Avg_RMSE=('mean_test_rmse', 'mean'),\n        Avg_MAE=('mean_test_mae', 'mean')\n    ).reset_index()\n\n    # Rename the parameter column for cleaner output\n    grouped_results = grouped_results.rename(columns={param_col: param_name})\n\n    # Sort by the parameter for consistent output\n    grouped_results = grouped_results.sort_values(by=param_name)\n\n    # Format the numerical columns to 3 decimal places\n    grouped_results['Avg_RMSE'] = grouped_results['Avg_RMSE'].map('{:.3f}'.format)\n    grouped_results['Avg_MAE'] = grouped_results['Avg_MAE'].map('{:.3f}'.format)\n\n    print(grouped_results.to_markdown(index=False))\n\n\n# Print tables for each hyperparameter\nfor param in sim_options.keys():\n    print_results_table(gs.cv_results, param)\n\nprint(\"\\n--- Best Scores and Parameters ---\")\nprint(f\"Best RMSE: {gs.best_score['rmse']:.3f}\")\nprint(f\"Best parameters for RMSE: {gs.best_params['rmse']}\")\nprint(f\"Best MAE: {gs.best_score['mae']:.3f}\")\nprint(f\"Best parameters for MAE: {gs.best_params['mae']}\")\n\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-12T01:44:41.386910Z","iopub.execute_input":"2025-06-12T01:44:41.387186Z","iopub.status.idle":"2025-06-12T01:44:41.405992Z","shell.execute_reply.started":"2025-06-12T01:44:41.387162Z","shell.execute_reply":"2025-06-12T01:44:41.404814Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'\\nreader = Reader(rating_scale=(0.5, 5))\\ndata = Dataset.load_from_df(filtered_ratings[[\\'userId\\', \\'movieId\\', \\'rating\\']], reader)\\n\\n# Define hyperparameter grid\\nsim_options = {\\n    \"n_factors\": [x * 50 for x in range(2,6)],\\n    \"n_epochs\": [x * 10 for x in range(4, 7)],\\n    \"lr_all\": [x / 50 for x in range(1,3)],\\n    \"reg_all\": [0.01, 0.02]\\n\\n}\\n#param_grid = {\"sim_options\": sim_options}\\n\\nsplit = 5\\ngs = GridSearchCV(SVD, sim_options,\\n                   measures=[\\'rmse\\', \\'mae\\'], cv=split, \\n                   n_jobs=6, refit=False)\\ngs.fit(data)\\n\\ndef print_results_table(gs_results, param_name):\\n    print(f\"\\nResults for \\'{param_name}\\':\")\\n    results_df = pd.DataFrame(gs_results)\\n\\n    # Filter columns to only include \\'mean_test_rmse\\', \\'mean_test_mae\\' and the parameter\\n    param_col = f\\'param_{param_name}\\'\\n    relevant_columns = [param_col, \\'mean_test_rmse\\', \\'mean_test_mae\\']\\n    filtered_results = results_df[relevant_columns]\\n\\n    # Group by the parameter and calculate the mean of RMSE and MAE\\n    # This is crucial because gs.cv_results contains all combinations,\\n    # so we need to average across other parameters for a clean view of one.\\n    grouped_results = filtered_results.groupby(param_col).agg(\\n        Avg_RMSE=(\\'mean_test_rmse\\', \\'mean\\'),\\n        Avg_MAE=(\\'mean_test_mae\\', \\'mean\\')\\n    ).reset_index()\\n\\n    # Rename the parameter column for cleaner output\\n    grouped_results = grouped_results.rename(columns={param_col: param_name})\\n\\n    # Sort by the parameter for consistent output\\n    grouped_results = grouped_results.sort_values(by=param_name)\\n\\n    # Format the numerical columns to 3 decimal places\\n    grouped_results[\\'Avg_RMSE\\'] = grouped_results[\\'Avg_RMSE\\'].map(\\'{:.3f}\\'.format)\\n    grouped_results[\\'Avg_MAE\\'] = grouped_results[\\'Avg_MAE\\'].map(\\'{:.3f}\\'.format)\\n\\n    print(grouped_results.to_markdown(index=False))\\n\\n\\n# Print tables for each hyperparameter\\nfor param in sim_options.keys():\\n    print_results_table(gs.cv_results, param)\\n\\nprint(\"\\n--- Best Scores and Parameters ---\")\\nprint(f\"Best RMSE: {gs.best_score[\\'rmse\\']:.3f}\")\\nprint(f\"Best parameters for RMSE: {gs.best_params[\\'rmse\\']}\")\\nprint(f\"Best MAE: {gs.best_score[\\'mae\\']:.3f}\")\\nprint(f\"Best parameters for MAE: {gs.best_params[\\'mae\\']}\")\\n'"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom surprise import Reader, Dataset, SVD, SlopeOne, accuracy\nimport time\nfrom surprise.model_selection import GridSearchCV, train_test_split\nfrom sklearn.model_selection import KFold\nimport pickle\n\nreader = Reader(rating_scale=(0.5, 5))\ndata = Dataset.load_from_df(filtered_ratings[['userId', 'movieId', 'rating']], reader)\n#best_model = SVD(n_factors = 200, n_epochs = 30, lr_all = 0.02, reg_all = 0.02)\nbest_model = pickle.load(open('/kaggle/input/mf/scikitlearn/default/1/matrix_fac.pickle', \"rb\"))\ntrainset, testset = train_test_split(data, test_size=0.2)\n\n#best_model.fit(trainset)\npredictions = best_model.test(testset)\ndef round_to_half(x):\n    return round(x * 2) / 2\n\nrounded_predictions = [\n    pred._replace(est=np.clip(round_to_half(pred.est), 0.5, 5.0))\n    for pred in predictions\n]\nprint(\"MSE: \", predictions)\nprint(\"Rounded MSE: \",accuracy.mse(rounded_predictions))\n\npickle.dump(best_model, open('matrix_fac.pickle', \"wb\"))\n\ni = 0\nj = 0\nprint(test.predict(i, j, r_ui= filtered_ratings[(filtered_ratings.userId==i)&(filtered_ratings.movieId==j)]['rating'].mean()))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_actor_average_ratings(df):\n    movies_df = df.copy()\n    actor_ratings = {}\n    order_columns = ['order_0', 'order_1', 'order_2', 'order_3', 'order_4']\n    \n    print(\"Calculating actor average ratings...\")\n    \n    for idx, row in movies_df.iterrows():\n        movie_rating = row['avg_rating']\n        if pd.isna(movie_rating):\n            continue\n            \n        for col in order_columns:\n            actor = row[col]\n            if pd.isna(actor) or actor == '':\n                continue\n            if actor not in actor_ratings:\n                actor_ratings[actor] = {'total_rating': 0, 'movie_count': 0}\n            \n            # Add rating and increment count\n            actor_ratings[actor]['total_rating'] += movie_rating\n            actor_ratings[actor]['movie_count'] += 1\n    \n    actor_avg_ratings = {}\n    for actor, data in actor_ratings.items():\n        actor_avg_ratings[actor] = data['total_rating'] / data['movie_count']\n    \n    all_actor_ratings = list(actor_avg_ratings.values())\n    overall_avg_rating = np.mean(all_actor_ratings) if all_actor_ratings else 0\n    \n    print(f\"Total unique actors: {len(actor_avg_ratings)}\")\n    print(f\"Overall average rating across all actors: {overall_avg_rating:.3f}\")\n    \n    print(\"Substituting actor average ratings in order columns...\")\n    \n    for col in order_columns:\n        movies_df[col] = movies_df[col].map(actor_avg_ratings)\n        movies_df[col] = movies_df[col].fillna(overall_avg_rating)\n    \n    print(\"Substitution completed!\")\n    \n    return movies_df, actor_avg_ratings, overall_avg_rating\n\n# Example usage and verification function\ndef verify_results(original_df, modified_df, actor_avg_ratings, overall_avg_rating):\n    \"\"\"\n    Verify the results and show some statistics\n    \"\"\"\n    print(\"\\n\" + \"=\"*50)\n    print(\"VERIFICATION RESULTS\")\n    print(\"=\"*50)\n    \n    order_columns = ['order_0', 'order_1', 'order_2', 'order_3', 'order_4']\n    \n    # Show sample of actor average ratings\n    print(f\"\\nSample of actor average ratings:\")\n    sample_actors = list(actor_avg_ratings.items())[:10]\n    for actor, rating in sample_actors:\n        print(f\"  {actor}: {rating:.3f}\")\n    \n    # Show statistics for order columns\n    print(f\"\\nOrder columns statistics (after substitution):\")\n    for col in order_columns:\n        non_null_count = modified_df[col].notna().sum()\n        avg_rating = modified_df[col].mean()\n        print(f\"  {col}: {non_null_count} non-null values, avg rating: {avg_rating:.3f}\")\n    \n    # Show before/after comparison for first few rows\n    print(f\"\\nBefore/After comparison (first 5 rows):\")\n    print(\"Original order columns:\")\n    print(original_df[order_columns].head())\n    print(\"\\nModified order columns (with average ratings):\")\n    print(modified_df[order_columns].head())\n\nmodified_df, actor_ratings, overall_avg = calculate_actor_average_ratings(movies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:41.449155Z","iopub.execute_input":"2025-06-12T01:44:41.449503Z","iopub.status.idle":"2025-06-12T01:44:41.934833Z","shell.execute_reply.started":"2025-06-12T01:44:41.449475Z","shell.execute_reply":"2025-06-12T01:44:41.933591Z"}},"outputs":[{"name":"stdout","text":"Calculating actor average ratings...\nTotal unique actors: 14814\nOverall average rating across all actors: 3.134\nSubstituting actor average ratings in order columns...\nSubstitution completed!\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\ngenres_clean = modified_df['genres'].fillna('').apply(lambda x: x if isinstance(x, list) else [])\ngenres_encoded = mlb.fit_transform(genres_clean)\ngenres_df = pd.DataFrame(genres_encoded, \n                        columns=[f'{genre}' for genre in mlb.classes_],\n                        index=modified_df.index)\nmodified_df = pd.concat([modified_df, genres_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:41.935833Z","iopub.execute_input":"2025-06-12T01:44:41.936148Z","iopub.status.idle":"2025-06-12T01:44:41.966616Z","shell.execute_reply.started":"2025-06-12T01:44:41.936124Z","shell.execute_reply":"2025-06-12T01:44:41.965757Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"modified_df.drop(columns=['description', 'title', 'director', 'soup','keywords'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:41.967714Z","iopub.execute_input":"2025-06-12T01:44:41.967974Z","iopub.status.idle":"2025-06-12T01:44:41.975893Z","shell.execute_reply.started":"2025-06-12T01:44:41.967953Z","shell.execute_reply":"2025-06-12T01:44:41.974860Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"modified_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:41.977211Z","iopub.execute_input":"2025-06-12T01:44:41.977614Z","iopub.status.idle":"2025-06-12T01:44:42.009810Z","shell.execute_reply.started":"2025-06-12T01:44:41.977582Z","shell.execute_reply":"2025-06-12T01:44:42.008758Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                              genres    id   order_0   order_1   order_2  \\\n0        [Animation, Comedy, Family]  2710  3.218628  3.571914  3.638176   \n1       [Adventure, Fantasy, Family]  3738  3.168370  3.760163  3.090169   \n5   [Action, Crime, Drama, Thriller]  1221  3.385523  3.363182  3.202128   \n8      [Adventure, Action, Thriller]  2006  3.337938  3.345751  3.013024   \n13               [Action, Adventure]   302  3.645755  3.158339  2.829485   \n\n     order_3   order_4  avg_rating  Action  Adventure  ...  History  Horror  \\\n0   3.216323  3.205199    3.598930       0          0  ...        0       0   \n1   3.760163  3.817607    3.760163       0          1  ...        0       0   \n5   3.126661  3.098204    3.905544       1          0  ...        0       0   \n8   2.893813  3.006704    2.740334       1          1  ...        0       0   \n13  3.459919  3.710181    3.710181       1          1  ...        0       0   \n\n    Music  Mystery  Romance  Science Fiction  TV Movie  Thriller  War  Western  \n0       0        0        0                0         0         0    0        0  \n1       0        0        0                0         0         0    0        0  \n5       0        0        0                0         0         1    0        0  \n8       0        0        0                0         0         1    0        0  \n13      0        0        0                0         0         0    0        0  \n\n[5 rows x 28 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genres</th>\n      <th>id</th>\n      <th>order_0</th>\n      <th>order_1</th>\n      <th>order_2</th>\n      <th>order_3</th>\n      <th>order_4</th>\n      <th>avg_rating</th>\n      <th>Action</th>\n      <th>Adventure</th>\n      <th>...</th>\n      <th>History</th>\n      <th>Horror</th>\n      <th>Music</th>\n      <th>Mystery</th>\n      <th>Romance</th>\n      <th>Science Fiction</th>\n      <th>TV Movie</th>\n      <th>Thriller</th>\n      <th>War</th>\n      <th>Western</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Animation, Comedy, Family]</td>\n      <td>2710</td>\n      <td>3.218628</td>\n      <td>3.571914</td>\n      <td>3.638176</td>\n      <td>3.216323</td>\n      <td>3.205199</td>\n      <td>3.598930</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>3738</td>\n      <td>3.168370</td>\n      <td>3.760163</td>\n      <td>3.090169</td>\n      <td>3.760163</td>\n      <td>3.817607</td>\n      <td>3.760163</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[Action, Crime, Drama, Thriller]</td>\n      <td>1221</td>\n      <td>3.385523</td>\n      <td>3.363182</td>\n      <td>3.202128</td>\n      <td>3.126661</td>\n      <td>3.098204</td>\n      <td>3.905544</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[Adventure, Action, Thriller]</td>\n      <td>2006</td>\n      <td>3.337938</td>\n      <td>3.345751</td>\n      <td>3.013024</td>\n      <td>2.893813</td>\n      <td>3.006704</td>\n      <td>2.740334</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[Action, Adventure]</td>\n      <td>302</td>\n      <td>3.645755</td>\n      <td>3.158339</td>\n      <td>2.829485</td>\n      <td>3.459919</td>\n      <td>3.710181</td>\n      <td>3.710181</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"modified_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:42.010907Z","iopub.execute_input":"2025-06-12T01:44:42.011260Z","iopub.status.idle":"2025-06-12T01:44:42.027589Z","shell.execute_reply.started":"2025-06-12T01:44:42.011238Z","shell.execute_reply":"2025-06-12T01:44:42.026220Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Index(['genres', 'id', 'order_0', 'order_1', 'order_2', 'order_3', 'order_4',\n       'avg_rating', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n       'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n       'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n       'Thriller', 'War', 'Western'],\n      dtype='object')"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nmovies = movies.reset_index(drop=True)\n\ntfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\ntfidf_matrix = tfidf_vectorizer.fit_transform(movies['soup'])\n\nmin_ratings = 100\nmax_ratings = 150\n\nuser_counts = ratings['userId'].value_counts()\neligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index.tolist()\n\nif not eligible_users:\n    print(\"No users found in this rating interval.\")\nelse:\n    selected_user = random.choice(eligible_users)\n    user_ratings = ratings[ratings['userId'] == selected_user]\n    user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n\n    print(f\"\\nSelected User ID: {selected_user}\")\n\n    selected_movie = user_movies.sample(1).iloc[0]\n    selected_movie_id = selected_movie['id']\n    selected_movie_index = movies[movies['id'] == selected_movie_id].index[0]\n\n    print(f\"\\nSelected Movie for Similarity Search: {selected_movie['title']} (Movie ID: {selected_movie_id})\")\n    cosine_sim = cosine_similarity(tfidf_matrix[selected_movie_index], tfidf_matrix).flatten()\n\n    similar_indices = cosine_sim.argsort()[::-1]\n    top_indices = [i for i in similar_indices if i != selected_movie_index][:15]\n\n    # Step 10: Print top 10 similar movies\n    print(\"\\nTop 15 Similar Movies:\")\n    for idx in top_indices:\n        print(f\"{movies.iloc[idx]['title']} (Similarity: {cosine_sim[idx]:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:18:18.950947Z","iopub.execute_input":"2025-06-12T02:18:18.951363Z","iopub.status.idle":"2025-06-12T02:18:19.408159Z","shell.execute_reply.started":"2025-06-12T02:18:18.951337Z","shell.execute_reply":"2025-06-12T02:18:19.406917Z"}},"outputs":[{"name":"stdout","text":"\nSelected User ID: 169281\n\nSelected Movie for Similarity Search: The Chorus (Movie ID: 773)\n\nTop 15 Similar Movies:\nZero for Conduct (Similarity: 0.2858)\nThe Chemical Brothers: Don't Think (Similarity: 0.2726)\nThe Duke Is Tops (Similarity: 0.2726)\nLes Misérables in Concert - The 25th Anniversary (Similarity: 0.2425)\nChapiteau-Show (Similarity: 0.2368)\nThe Heat's On (Similarity: 0.2368)\nRadio Day (Similarity: 0.2368)\nFive Dances (Similarity: 0.2299)\nDiabolique (Similarity: 0.2165)\nThe Hessen Affair (Similarity: 0.2101)\nMädchen in Uniform (Similarity: 0.2099)\nJesus Christ Superstar (Similarity: 0.2098)\nThe Age of Love (Similarity: 0.2025)\nStill Bill (Similarity: 0.1843)\nOfficial Rejection (Similarity: 0.1798)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\ntfidf_matrix = tfidf_vectorizer.fit_transform(movies['soup'])\n\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n                       columns=tfidf_vectorizer.get_feature_names_out(),\n                       index=movies.index)\n\nprint(f\"Tf-idf matrix shape: \", tfidf_matrix.shape)\n\nmovie_id_to_index = {movie_id: i for i, movie_id in enumerate(movies['id'])}\nfor i in range(1,5):\n    min_ratings = i * 100\n    max_ratings = min_ratings + 50\n\n    print(f\"\\nRating Interval: [{min_ratings}, {max_ratings})\")\n    \n    # Select all users within the rating count interval\n    user_counts = ratings['userId'].value_counts()\n    eligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index\n\n    if len(eligible_users) == 0:\n        print(\"No users in this rating interval. Skipping...\")\n        continue\n\n    lr_mse_list = []\n    lr_mae_list = []\n    ridge_mse_list = []\n    ridge_mae_list = []\n\n    for user_id in eligible_users:\n        user_ratings = ratings[ratings['userId'] == user_id]\n        user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n\n        user_movie_indices = [movie_id_to_index.get(movie_id) for movie_id in user_movies['id'].values]\n        user_movie_indices = [idx for idx in user_movie_indices if idx is not None]\n\n        if len(user_movie_indices) < 5:\n            continue\n\n        X = tfidf_matrix[user_movie_indices]\n        y = user_movies.loc[user_movies['id'].isin(\n            [movies['id'].iloc[idx] for idx in user_movie_indices]), 'rating'].values\n\n        if len(y) < 5:\n            continue\n\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n            # Linear Regression\n            lr_model = LinearRegression()\n            lr_model.fit(X_train, y_train)\n            lr_pred_raw = lr_model.predict(X_test)\n            lr_pred = np.round(lr_pred_raw * 2) / 2\n            lr_pred = np.clip(lr_pred, 0.5, 5.0)\n\n            lr_mse = mean_squared_error(y_test, lr_pred)\n            lr_mae = mean_absolute_error(y_test, lr_pred)\n            lr_mse_list.append(lr_mse)\n            lr_mae_list.append(lr_mae)\n\n            # Ridge (SGDRegressor)\n            sgd_model = SGDRegressor(penalty='l2', alpha=0.01, random_state=42)\n            sgd_model.fit(X_train, y_train)\n            ridge_pred_raw = sgd_model.predict(X_test)\n            ridge_pred = np.round(ridge_pred_raw * 2) / 2\n            ridge_pred = np.clip(ridge_pred, 0.5, 5.0)\n\n            ridge_mse = mean_squared_error(y_test, ridge_pred)\n            ridge_mae = mean_absolute_error(y_test, ridge_pred)\n            ridge_mse_list.append(ridge_mse)\n            ridge_mae_list.append(ridge_mae)\n\n        except Exception as e:\n            continue\n\n    # Report averages for this interval\n    if lr_mse_list:\n        print(\"Average Model Evaluation:\")\n        print(f\"Linear Regression - MSE: {np.mean(lr_mse_list):.4f}, MAE: {np.mean(lr_mae_list):.4f}\")\n        print(f\"Ridge (SGDRegressor) - MSE: {np.mean(ridge_mse_list):.4f}, MAE: {np.mean(ridge_mae_list):.4f}\")\n    else:\n        print(\"Not enough valid users/data to compute average metrics.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:47:19.935560Z","iopub.execute_input":"2025-06-12T01:47:19.935957Z","iopub.status.idle":"2025-06-12T02:00:55.083447Z","shell.execute_reply.started":"2025-06-12T01:47:19.935932Z","shell.execute_reply":"2025-06-12T02:00:55.082010Z"}},"outputs":[{"name":"stdout","text":"Tf-idf matrix shape:  (5634, 5000)\n\nRating Interval: [100, 150)\nAverage Model Evaluation:\nLinear Regression - MSE: 0.9923, MAE: 0.7571\nRidge (SGDRegressor) - MSE: 4.2617, MAE: 1.8526\n\nRating Interval: [200, 250)\nAverage Model Evaluation:\nLinear Regression - MSE: 1.0463, MAE: 0.7795\nRidge (SGDRegressor) - MSE: 2.9519, MAE: 1.4969\n\nRating Interval: [300, 350)\nAverage Model Evaluation:\nLinear Regression - MSE: 1.1101, MAE: 0.8042\nRidge (SGDRegressor) - MSE: 2.4330, MAE: 1.3357\n\nRating Interval: [400, 450)\nAverage Model Evaluation:\nLinear Regression - MSE: 1.1967, MAE: 0.8395\nRidge (SGDRegressor) - MSE: 2.1220, MAE: 1.2285\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"'''\ncount = CountVectorizer(min_df=3, max_df=0.95, stop_words='english', max_features=5000)\ncount_data = count.fit_transform(movies['description'])\n\ntransformer = TfidfTransformer()\ntrans_data = transformer.fit_transform(count_data)\n'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:44:42.665465Z","iopub.status.idle":"2025-06-12T01:44:42.665744Z","shell.execute_reply.started":"2025-06-12T01:44:42.665614Z","shell.execute_reply":"2025-06-12T01:44:42.665626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_columns = [\n    'order_0', 'order_1', 'order_2', 'order_3', 'order_4',\n    'avg_rating', 'Action', 'Adventure', 'Animation', 'Comedy', 'Crime',\n    'Documentary', 'Drama', 'Family', 'Fantasy', 'Foreign', 'History',\n    'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction', 'TV Movie',\n    'Thriller', 'War', 'Western'\n]\n\nmovies_features = modified_df[feature_columns].copy()\nmovies_features.fillna(0, inplace=True) \n\nscaler = StandardScaler()\nscaled_movie_features = scaler.fit_transform(movies_features)\nscaled_movie_features_df = pd.DataFrame(scaled_movie_features, columns=feature_columns, index=movies.index)\n\n\nprint(f\"Movie features shape: {scaled_movie_features_df.shape}\")\nmovie_id_to_index = {movie_id: i for i, movie_id in enumerate(movies['id'])}\n\nfor i in range(1, 10):\n    min_ratings = i * 50\n    max_ratings = min_ratings + 50\n\n    print(f\"\\nRating Interval: [{min_ratings}, {max_ratings})\")\n\n    # Select all users within the rating count interval\n    user_counts = ratings['userId'].value_counts()\n    eligible_users = user_counts[(user_counts >= min_ratings) & (user_counts < max_ratings)].index\n\n    if len(eligible_users) == 0:\n        print(\"No users in this rating interval. Skipping...\")\n        continue\n\n    lr_mse_list = []\n    lr_mae_list = []\n    ridge_mse_list = []\n    ridge_mae_list = []\n\n    for user_id in eligible_users:\n        user_ratings = ratings[ratings['userId'] == user_id]\n        user_movies = user_ratings.merge(movies, left_on='movieId', right_on='id')\n\n        user_movie_indices = [movie_id_to_index.get(movie_id) for movie_id in user_movies['id'].values]\n        user_movie_indices = [idx for idx in user_movie_indices if idx is not None]\n\n        if len(user_movie_indices) < 5: # Need at least 5 data points for train/test split\n            continue\n\n        X = scaled_movie_features_df.iloc[user_movie_indices].values\n        y = user_movies.loc[user_movies['id'].isin(\n            [movies['id'].iloc[idx] for idx in user_movie_indices]), 'rating'].values\n\n        if len(y) < 5: \n            continue\n\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n            # Linear Regression\n            lr_model = LinearRegression()\n            lr_model.fit(X_train, y_train)\n            lr_pred_raw = lr_model.predict(X_test)\n            lr_pred = np.round(lr_pred_raw * 2) / 2\n            lr_pred = np.clip(lr_pred, 0.5, 5.0)\n\n            lr_mse = mean_squared_error(y_test, lr_pred)\n            lr_mae = mean_absolute_error(y_test, lr_pred)\n            lr_mse_list.append(lr_mse)\n            lr_mae_list.append(lr_mae)\n\n            # Ridge (SGDRegressor)\n            sgd_model = SGDRegressor(penalty='l2', alpha=0.01, random_state=42, max_iter=1000) # Added max_iter\n            sgd_model.fit(X_train, y_train)\n            ridge_pred_raw = sgd_model.predict(X_test)\n            ridge_pred = np.round(ridge_pred_raw * 2) / 2\n            ridge_pred = np.clip(ridge_pred, 0.5, 5.0)\n\n            ridge_mse = mean_squared_error(y_test, ridge_pred)\n            ridge_mae = mean_absolute_error(y_test, ridge_pred)\n            ridge_mse_list.append(ridge_mse)\n            ridge_mae_list.append(ridge_mae)\n\n        except Exception as e:\n            continue\n    if lr_mse_list:\n        print(\"Average Model Evaluation:\")\n        print(f\"Linear Regression - MSE: {np.mean(lr_mse_list):.4f}, MAE: {np.mean(lr_mae_list):.4f}\")\n        print(f\"Ridge (SGDRegressor) - MSE: {np.mean(ridge_mse_list):.4f}, MAE: {np.mean(ridge_mae_list):.4f}\")\n    else:\n        print(\"Not enough valid users/data to compute average metrics.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:19:46.135709Z","iopub.execute_input":"2025-06-12T02:19:46.136162Z"}},"outputs":[{"name":"stdout","text":"Movie features shape: (5634, 26)\n\nRating Interval: [50, 100)\nAverage Model Evaluation:\nLinear Regression - MSE: 1.2721, MAE: 0.8363\nRidge (SGDRegressor) - MSE: 1.5101, MAE: 0.9100\n\nRating Interval: [100, 150)\n","output_type":"stream"}],"execution_count":null}]}